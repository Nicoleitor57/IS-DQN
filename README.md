# $\text{IS-DQN}$: Reinforcement Learning con Estructura de Informaci√≥n y PSR para POMDPs üß†

Este proyecto implementa y eval√∫a varias arquitecturas de **Deep Q-Network (DQN)** que incorporan la **Estructura de Informaci√≥n (IS)** y las **Representaciones de Estado Predictivas (PSR)** como un *sesgo inductivo* expl√≠cito. El objetivo es mejorar la eficiencia en la representaci√≥n de la historia y el rendimiento del agente en entornos de **Proceso de Decisi√≥n de Markov Parcialmente Observable (POMDP)**.

***

## 1. Fundamento Te√≥rico: Estructura de Informaci√≥n y PSR

### 1.1 El Marco de la Estructura de Informaci√≥n (IS)

La **Estructura de Informaci√≥n** de un problema de toma de decisiones secuencial describe las dependencias causales entre las variables del sistema. El *paper* formaliza este concepto a trav√©s de:

* **Modelos Generales (POST/POSG):** Propone los modelos **Partially-Observable Sequential Teams (POST)** y **Games (POSG)**, que contienen una representaci√≥n expl√≠cita de la estructura de informaci√≥n.
* **Estado Estructural-Informativo ($\mathbb{I}_{h}^{\dagger}$):** Esta es la cantidad central para el an√°lisis de complejidad. Se define como el conjunto m√≠nimo de variables pasadas (observables o latentes) que son suficientes para *d-separar* las observaciones pasadas de las observaciones futuras en el grafo causal del sistema.
* **Tractabilidad:** El tama√±o de este estado estructural-informativo ($|\mathbb{I}_{h}^{\dagger}|$) caracteriza la complejidad del sistema. Cuando este tama√±o es modesto, el problema se vuelve estad√≠sticamente tratable.

### 1.2 PSR como Representaci√≥n de Estado Eficaz

Las **Representaciones de Estado Predictivas (PSR)** modelan la din√°mica del sistema bas√°ndose en la predicci√≥n de eventos futuros ("tests") dada la historia pasada, sin modelar expl√≠citamente un estado latente.

* El **rango de la din√°mica** de un problema (una medida de su complejidad) est√° acotado por el tama√±o del estado estructural-informativo $|\mathbb{I}_{h}^{\dagger}|$.
* Esto implica que un embedding de PSR (una representaci√≥n del estado) puede construirse con una dimensi√≥n m√°xima igual a $|\mathbb{I}_{h}^{\dagger}|$, proporcionando una parametrizaci√≥n robusta y eficiente para el aprendizaje.

***

## 2. Implementaciones del Proyecto: Variantes de PSR+DQN

Este repositorio implementa y compara tres arquitecturas DQN diferentes para el entorno **Two-Tigers POMDP**, cada una con un nivel creciente de sesgo inductivo de PSR. Todas las variantes utilizan un c√°lculo de *oracle Bayesian belief updates* (creencia perfecta) para las posiciones del tigre.

| Variante | Archivo | Caracter√≠sticas de Entrada (DQN) | M√©todo de Extracci√≥n de Features | √ânfasis Te√≥rico |
| :--- | :--- | :--- | :--- | :--- |
| **1. Baseline (DQN + Belief)** | `IS_tigers.py` | Vector de creencia de 4-dim (probabilidades por tigre) | Ninguno | Comportamiento Base en el espacio de Creencia. |
| **2. PSR Aprendido (Online)** | `IS_tigers_2.py` | Vector de creencia (4-dim) + 2-dim de predicciones PSR aprendidas | Red Neuronal (NN) entrenada en l√≠nea para predecir $P(O_L \mid listen)$ | Aproximaci√≥n simple de PSR basada en tests. |
| **3. PSR Espectral (Offline)** | `IS_tigers_3.py` | Vector de creencia (4-dim) + $r$-dim de embedding PSR (default $r=2$) | Descomposici√≥n SVD de la matriz Historia √ó Test ($P_{HT}$) recolectada en una fase de *warmup* | Aplicaci√≥n directa de la teor√≠a PSR espectral. |

### Componentes Clave del C√≥digo
* **`IS/DQN.py`**: Contiene las clases base del agente DQN, incluyendo `QNet` y `ReplayBuffer`.
* **Entornos**: Los entornos POMDP utilizados (como el `TwoTigersEnv.py`) son esenciales para probar la robustez de las representaciones de estado en condiciones de observaci√≥n parcial.

***

## 3. Pr√≥ximos Pasos / Extensiones Sugeridas üöÄ

1. **Evaluaci√≥n Estad√≠stica con M√∫ltiples Semillas:**
   * Ejecutar cada variante con **5‚Äì10 semillas** y reportar la media ¬± desviaci√≥n est√°ndar o intervalo de confianza para validar la significancia estad√≠stica.

2. **Integraci√≥n de Arquitecturas Recurrentes (DRQN):**
   * Reemplazar la Q-Network *feedforward* con una red recurrente (GRU/LSTM) e incorporar los features PSR.

3. **An√°lisis de Sensibilidad a la $\alpha$-Robustez:**
   * Evaluar c√≥mo la elecci√≥n del rango $r$ en la PSR espectral afecta la estabilidad y el rendimiento del DQN.

4. **Extensi√≥n a Estructuras de Informaci√≥n Alternativas:**
   * Aplicar los m√©todos PSR-DQN a otros entornos con estructuras de informaci√≥n conocidas (ej. memoria limitada).

***

## 4. Uso y Ejecuci√≥n

Aseg√∫rate de tener instaladas las dependencias (`torch`, `numpy`, `gymnasium`, `tensorboard`).

### Ejecuci√≥n de las Variantes Two-Tigers

```bash
# 1. Baseline: DQN + Oracle Belief
python -m IS.IS_tigers

# 2. PSR Aprendido (Online) + DQN
python -m IS.IS_tigers_2

# 3. PSR Espectral (Offline SVD) + DQN
python -m IS.IS_tigers_3
