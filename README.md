# RL y Estructura de Informaci칩n en POMDPs

Este repositorio explora los conceptos del paper "On the Role of Information Structure..." (Altabaa & Yang, 2024) aplicando sus ideas te칩ricas a modelos de caja negra (DRQN/LSTM).

El objetivo es medir c칩mo diferentes **estructuras de informaci칩n** (implementadas como entornos POMDP personalizados) desaf칤an la capacidad de un agente DRQN est치ndar para aprender una pol칤tica 칩ptima.

---

## 游 Configuraci칩n y Entorno

Este proyecto utiliza **Python 3.11** y se gestiona con `conda`.

### Instalaci칩n

1.  **Clona el repositorio:**
    ```bash
    git clone https://github.com/Nicoleitor57/IS-DQN.git
    cd IS-DQN
    ```

2.  **Crea y activa el entorno de Conda:**
    ```bash
    # Crea el entorno con la versi칩n correcta de Python
    conda create -n rl_info python=3.11
    
    # Activa el entorno
    conda activate rl_info
    ```

3.  **Instala las dependencias:**
    ```bash
    # (Aseg칰rate de tener un archivo requirements.txt con [gymnasium, ray[rllib], torch])
    pip install -r requirements.txt
    ```

---

## 游댧 Entornos de Prueba

El n칰cleo de este proyecto son cuatro entornos POMDP dise침ados a medida, cada uno para probar una debilidad espec칤fica de los modelos de memoria "black-box" (como un LSTM).

### 1. POKeyDoorEnv (El Baseline: POMDP vs. MDP)

* **Concepto Central:** Un agente en un mundo de cuadr칤cula (grid world) simple con observabilidad parcial.
* **Objetivo:** El agente debe encontrar una llave y luego navegar hasta una puerta.
* **El Desaf칤o (Observabilidad Parcial):** El agente solo ve una cuadr칤cula de 3x3 a su alrededor.
    * Esto crea **"aliasing de estados"**: m칰ltiples ubicaciones en el mapa (estados latentes $S_t$) se ven id칠nticas (misma observaci칩n $O_t$). Por ejemplo, cualquier pasillo vac칤o se ve igual.
* **Modelo Puesto a Prueba:**
    * Un **DQN est치ndar (sin memoria)** fracasar치. Es reactivo (solo usa $O_t$) y no puede "recordar" si ya recogi칩 la llave o distinguir pasillos id칠nticos.
    * Un **DRQN (con LSTM)** deber칤a tener 칠xito. El LSTM integra el historial de observaciones para construir un "estado de creencia" ($b_t$) que desambigua la situaci칩n.

### 2. KeyDoorMazeEnv (El Desaf칤o: Memoria a Largo Plazo)

* **Concepto Central:** Una versi칩n avanzada del `POKeyDoorEnv` dise침ada para probar la memoria a largo plazo.
* **Objetivo:** El agente debe recoger una llave espec칤fica (ej. **Llave Roja**) y navegar a la puerta del color correspondiente (ej. **Puerta Roja**).
* **El Desaf칤o (Ruido y Distancia):**
    1.  **Memoria de 1-bit:** El agente debe recordar un solo bit crucial (el color de la llave).
    2.  **Distancia:** La llave y las puertas est치n en extremos opuestos del mapa, forzando un largo viaje (30-50 pasos) a trav칠s de pasillos "ruidosos" (observaciones irrelevantes).
* **Modelo Puesto a Prueba:**
    * Este entorno ataca el **desvanecimiento de gradientes (vanishing gradients)**.
    * Un **DRQN (LSTM)** intentar치 mantener ese "bit de color" en su estado oculto. Sin embargo, es probable que esta informaci칩n se degrade o se "olvide" despu칠s de 50 pasos de procesar observaciones irrelevantes.
    * Se alinea con el paper (Fig. 2d): el estado info-estructural ($\mathcal{I}_h^\dagger$) es m칤nimo (solo $o_{t-k}$), pero est치 causalmente distante de la acci칩n $a_t$.

```python
class KeyDoorMazeEnv(gym.Env):
    """
    Entorno de Laberinto con Llave y Puerta Parcialmente Observable (PO-KeyDoor)
    
    Compatible con Gymnasium.
    
    Objetivo:
    El agente debe recoger una llave (Roja o Azul) y luego ir a la
    puerta del color correspondiente para obtener una gran recompensa.
    Elegir la puerta incorrecta resulta en un gran castigo.
    
    Observabilidad Parcial:
    El agente solo ve una cuadr칤cula de 3x3 a su alrededor.
    
    Valores del Grid:
    - 0: Piso (vac칤o)
    - 1: Muro
    - 2: Llave Roja
    - 3: Llave Azul
    - 4: Puerta Roja
    - 5: Puerta Azul
    
    Espacio de Observaci칩n (3x3 Box):
    Igual que los valores del grid, pero 6 es el Agente (en la celda 1,1).
    
    Acciones:
    - 0: Arriba
    - 1: Abajo
    - 2: Izquierda
    - 3: Derecha
    
    Estado Info-Estructural (Oculto):
    El estado latente clave es `self._has_key` (0=no, 2=roja, 3=azul).
    Un DRQN debe inferir y *recordar* este estado desde t_llave hasta t_puerta.
    """
