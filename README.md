# $\text{IS-DQN}$: Reinforcement Learning con Estructura de Informaci√≥n y PSR para POMDPs üß†

Este proyecto implementa y eval√∫a varias arquitecturas de **Deep Q-Network (DQN)** que incorporan la **Estructura de Informaci√≥n (IS)** y las **Representaciones de Estado Predictivas (PSR)** como un *sesgo inductivo* expl√≠cito. El objetivo es mejorar la eficiencia en la representaci√≥n de la historia y el rendimiento del agente en entornos de **Proceso de Decisi√≥n de Markov Parcialmente Observable (POMDP)**.

***

## 1. Fundamento Te√≥rico: Estructura de Informaci√≥n y PSR

### 1.1 El Marco de la Estructura de Informaci√≥n (IS)

[cite_start]La **Estructura de Informaci√≥n** de un problema de toma de decisiones secuencial describe las dependencias causales entre las variables del sistema[cite: 1]. El *paper* formaliza este concepto a trav√©s de:

* [cite_start]**Modelos Generales (POST/POSG):** Propone los modelos **Partially-Observable Sequential Teams (POST)** y **Games (POSG)**, que contienen una representaci√≥n expl√≠cita de la estructura de informaci√≥n[cite: 1].
* [cite_start]**Estado Estructural-Informativo ($\mathbb{I}_{h}^{\dagger}$):** Esta es la cantidad central para el an√°lisis de complejidad[cite: 1]. [cite_start]Se define como el conjunto m√≠nimo de variables pasadas (observables o latentes) que son suficientes para *d-separar* las observaciones pasadas de las observaciones futuras en el grafo causal del sistema[cite: 1].
* [cite_start]**Tractabilidad:** El tama√±o de este estado estructural-informativo ($|\mathbb{I}_{h}^{\dagger}|$) caracteriza la complejidad del sistema[cite: 1]. [cite_start]Cuando este tama√±o es modesto, el problema se vuelve estad√≠sticamente tratable[cite: 1].

### 1.2 PSR como Representaci√≥n de Estado Eficaz

[cite_start]Las **Representaciones de Estado Predictivas (PSR)** modelan la din√°mica del sistema bas√°ndose en la predicci√≥n de eventos futuros ("tests") dada la historia pasada, sin modelar expl√≠citamente un estado latente[cite: 1].

* [cite_start]El **rango de la din√°mica** de un problema (una medida de su complejidad) est√° acotado por el tama√±o del estado estructural-informativo $|\mathbb{I}_{h}^{\dagger}|$[cite: 1].
* [cite_start]Esto implica que un embedding de PSR (una representaci√≥n del estado) puede construirse con una dimensi√≥n m√°xima igual a $|\mathbb{I}_{h}^{\dagger}|$, proporcionando una parametrizaci√≥n robusta y eficiente para el aprendizaje[cite: 1].

***

## 2. Implementaciones del Proyecto: Variantes de PSR+DQN

Este repositorio implementa y compara tres arquitecturas DQN diferentes para el entorno **Two-Tigers POMDP**, cada una con un nivel creciente de sesgo inductivo de PSR. [cite_start]Todas las variantes utilizan un c√°lculo de *oracle Bayesian belief updates* (creencia perfecta) para las posiciones del tigre[cite: 2].

| Variante | Archivo | Caracter√≠sticas de Entrada (DQN) | M√©todo de Extracci√≥n de Features | √ânfasis Te√≥rico |
| :--- | :--- | :--- | :--- | :--- |
| **1. Baseline (DQN + Belief)** | `IS_tigers.py` | [cite_start]Vector de creencia de 4-dim (probabilidades por tigre) [cite: 2] | [cite_start]Ninguno [cite: 2] | [cite_start]Comportamiento Base en el espacio de Creencia[cite: 2]. |
| **2. PSR Aprendido (Online)** | `IS_tigers_2.py` | [cite_start]Vector de creencia (4-dim) + 2-dim de predicciones PSR aprendidas [cite: 2] | [cite_start]Red Neuronal (NN) entrenada en l√≠nea para predecir $P(O_L \mid listen)$ [cite: 2] | [cite_start]Aproximaci√≥n simple de PSR basada en tests[cite: 2]. |
| **3. PSR Espectral (Offline)** | `IS_tigers_3.py` | [cite_start]Vector de creencia (4-dim) + $r$-dim de embedding PSR (default $r=2$) [cite: 2] | [cite_start]Descomposici√≥n SVD de la matriz Historia $\times$ Test ($P_{HT}$) recolectada en una fase de *warmup* [cite: 2] | [cite_start]Aplicaci√≥n directa de la teor√≠a PSR espectral[cite: 2]. |

### Componentes Clave del C√≥digo
* [cite_start]**`IS/DQN.py`**: Contiene las clases base del agente DQN, incluyendo `QNet` y `ReplayBuffer`[cite: 3].
* **Entornos**: Los entornos POMDP utilizados (como el `TwoTigersEnv.py`) son esenciales para probar la robustez de las representaciones de estado en condiciones de observaci√≥n parcial.

***

## 3. Pr√≥ximos Pasos / Extensiones Sugeridas üöÄ

1.  **Evaluaci√≥n Estad√≠stica con M√∫ltiples Semillas:**
    * Ejecutar cada variante con **5‚Äì10 semillas** y reportar la media ¬± desviaci√≥n est√°ndar o intervalo de confianza para validar la significancia estad√≠stica.
2.  **Integraci√≥n de Arquitecturas Recurrentes (DRQN):**
    * [cite_start]Reemplazar la Q-Network *feedforward* con una red recurrente (GRU/LSTM) e incorporar los features PSR[cite: 2].
3.  **An√°lisis de Sensibilidad a la $\alpha$-Robustez:**
    * Evaluar c√≥mo la elecci√≥n del rango $r$ en la PSR espectral afecta la estabilidad y el rendimiento del DQN.
4.  **Extensi√≥n a Estructuras de Informaci√≥n Alternativas:**
    * [cite_start]Aplicar los m√©todos PSR-DQN a otros entornos con estructuras de informaci√≥n conocidas (ej. memoria limitada)[cite: 2].

***

## 4. Uso y Ejecuci√≥n

Aseg√∫rate de tener instaladas las dependencias (`torch`, `numpy`, `gymnasium`, `tensorboard`).

### Ejecuci√≥n de las Variantes Two-Tigers

```bash
# 1. Baseline: DQN + Oracle Belief
python -m IS.IS_tigers

# 2. PSR Aprendido (Online) + DQN
python -m IS.IS_tigers_2

# 3. PSR Espectral (Offline SVD) + DQN
python -m IS.IS_tigers_3
